{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[-0.2988,  0.0702,  0.0528]],\n",
      "\n",
      "        [[ 0.1779, -0.4344, -0.2638]]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "test_conv = nn.Conv1d(1,2,3)\n",
    "print(test_conv.weight)\n",
    "with torch.no_grad():\n",
    "    test_conv.weight *= torch.zeros((1,1,1))\n",
    "# print(test_conv.weight)\n",
    "# input = torch.ones(1,1,10)\n",
    "# test_conv(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalConv(nn.Module):\n",
    "    '''CausalConv resembling pixelCNN a bit more than some implementations'''\n",
    "    def __init__(self,through_channels, inter_channels, dilation=1, kernel_size = 5):\n",
    "        super(CausalConv,self).__init__()\n",
    "        \n",
    "        assert(kernel_size%2 == 1)\n",
    "        assert(kernel_size >= 5)\n",
    "\n",
    "        filter_mask = torch.tensor([1 for i in range(kernel_size//2)] + \n",
    "                                        [0 for i in range (-(-kernel_size//2))])\n",
    "        self.register_buffer('filter_mask', filter_mask)\n",
    "\n",
    "        self.conv_sig = nn.Conv1d(through_channels,\n",
    "                                  inter_channels,\n",
    "                                  kernel_size,\n",
    "                                  dilation=dilation,\n",
    "                                  padding='same'\n",
    "                                  )\n",
    "        self.conv_tanh = nn.Conv1d(through_channels,\n",
    "                                  inter_channels,\n",
    "                                  kernel_size,\n",
    "                                  dilation=dilation,\n",
    "                                  padding='same'\n",
    "                                  )\n",
    "        self.one_by_one = nn.Conv1d(inter_channels,\n",
    "                                    through_channels,\n",
    "                                    kernel_size=1\n",
    "                                    )\n",
    "\n",
    "                               \n",
    "\n",
    "    \n",
    "    def forward(self,inputs):\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            self.conv_sig.weight = nn.parameter.Parameter(self.conv_sig.weight * self.get_buffer('filter_mask'))\n",
    "            self.conv_tanh.weight = nn.parameter.Parameter(self.conv_tanh.weight * self.get_buffer('filter_mask'))\n",
    "\n",
    "        sig_a = self.conv_sig(inputs)\n",
    "        sig_a = nn.Sigmoid()(sig_a)\n",
    "\n",
    "        tanh_a = self.conv_tanh(inputs)\n",
    "        tanh_a = nn.Tanh()(tanh_a)\n",
    "\n",
    "        x = sig_a * tanh_a\n",
    "        x = self.one_by_one(x)\n",
    "        res = x + inputs\n",
    "\n",
    "        return res, x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 20])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0968,  0.0684,  0.0750,  0.1298,  0.0374,  0.0773,  0.1119,\n",
       "           0.1175,  0.0786,  0.1402,  0.1527,  0.1313,  0.1370,  0.1197,\n",
       "           0.1183,  0.1229,  0.1656,  0.1269,  0.1543,  0.1618],\n",
       "         [-0.0642, -0.0615, -0.0510, -0.0075, -0.0370, -0.0304, -0.0321,\n",
       "          -0.0373, -0.0418, -0.0307, -0.0200, -0.0246, -0.0232, -0.0245,\n",
       "          -0.0412, -0.0543, -0.0361, -0.0441, -0.0374, -0.0257],\n",
       "         [-0.2599, -0.2539, -0.1947, -0.1878, -0.1781, -0.1888, -0.1548,\n",
       "          -0.1918, -0.1858, -0.1306, -0.1698, -0.1474, -0.1481, -0.1660,\n",
       "          -0.1992, -0.1817, -0.1976, -0.1906, -0.1811, -0.1604]]],\n",
       "       grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = CausalConv(3,5)\n",
    "input = torch.rand((1,3,20))\n",
    "# print(input)\n",
    "layer(input)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ec606fc085fe86530c35cef2373cc343a007c8f5f2b5ac3b7e79a3e17604272c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('lab1': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
